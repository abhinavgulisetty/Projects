# -*- coding: utf-8 -*-
"""HitPotentialSongs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QgRu7rbgaDc7eUW4ck1mqt0YiTUXDV3l
"""

#Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score

file_path = 'Spotify Most Streamed Songs.csv'
data = pd.read_csv(file_path)

data['streams'] = pd.to_numeric(data['streams'], errors='coerce')
columns_to_convert = ['in_deezer_playlists', 'in_shazam_charts']
for col in columns_to_convert:
    data[col] = pd.to_numeric(data[col], errors='coerce')

data_cleaned = data.dropna(subset=['streams'])
numeric_cols = data_cleaned.select_dtypes(include=['int64', 'float64']).columns
data_cleaned.loc[:, numeric_cols] = data_cleaned[numeric_cols].fillna(data_cleaned[numeric_cols].median())
data_cleaned = data_cleaned.drop(['cover_url', 'track_name', 'artist(s)_name'], axis=1)

data_cleaned['hit_potential'] = np.where(data_cleaned['in_spotify_charts'] > 0, 1, 0)

X = data_cleaned.drop(['in_spotify_charts', 'hit_potential'], axis=1)
y = data_cleaned['hit_potential']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

numeric_features = ['artist_count', 'released_year', 'released_month', 'released_day', 'streams',
                    'in_spotify_playlists', 'in_apple_playlists', 'in_apple_charts', 'in_deezer_playlists',
                    'in_deezer_charts', 'in_shazam_charts', 'bpm', 'danceability_%', 'valence_%',
                    'energy_%', 'acousticness_%', 'instrumentalness_%', 'liveness_%', 'speechiness_%']
categorical_features = ['key', 'mode']

numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

models = {
    'Random Forest': RandomForestClassifier(random_state=42),
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'SVM': SVC(),
    'Gradient Boosting': GradientBoostingClassifier(random_state=42),
    'K-Nearest Neighbors': KNeighborsClassifier(),
    'Decision Tree': DecisionTreeClassifier(random_state=42)
}

results = {}

for name, model in models.items():
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])

    pipeline.fit(X_train, y_train)

    y_pred = pipeline.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)

    results[name] = {
        'accuracy': accuracy,
        'classification_report': report
    }

for name, result in results.items():
    print(f"\nModel: {name}")
    print(f"Accuracy: {result['accuracy']:.4f}")
    print(f"Classification Report:")
    print(pd.DataFrame(result['classification_report']).transpose())

print("\nCross-Validation Scores:")
for name, model in models.items():
    pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', model)])
    cv_scores = cross_val_score(pipeline, X, y, cv=5)
    print(f"{name}: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")